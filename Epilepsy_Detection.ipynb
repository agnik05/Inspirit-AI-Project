{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Epilepsy Detection",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmuz1G095NMO",
        "cellView": "form"
      },
      "source": [
        "#@title ##Import libraries!\n",
        "\n",
        "!pip -q install pyngrok\n",
        "!pip -q install streamlit\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, SimpleRNN, LSTM\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "monitor = ModelCheckpoint('./model.hdf5', \n",
        "                          monitor='val_accuracy', \n",
        "                          verbose=0, \n",
        "                          save_best_only=True, \n",
        "                          save_weights_only=False, \n",
        "                          mode='auto', \n",
        "                          save_freq='epoch')\n",
        "\n",
        "import gdown\n",
        "\n",
        "## Set random seed for reproducible results\n",
        "RAND_SEED = 12\n",
        "np.random.seed(RAND_SEED)\n",
        "tf.random.set_seed(RAND_SEED)\n",
        "\n",
        "## Utils function to combine 23 chunks from the same patient into one big chunk\n",
        "def prepare_data(eeg_df):\n",
        "  file_names = eeg_df['Unnamed: 0'].tolist()\n",
        "\n",
        "  subject_ids = []\n",
        "  chunk_ids = []\n",
        "  for fn in file_names:\n",
        "    subject_ids.append(fn.split('.')[-1])\n",
        "    chunk_ids.append(fn.split('.')[0])\n",
        "  subject_ids = list(set(subject_ids))\n",
        "  assert len(subject_ids) == 500\n",
        "\n",
        "  sub2ind = {}\n",
        "  for ind, sub in enumerate(subject_ids):\n",
        "    sub2ind[sub] = ind\n",
        "\n",
        "  eeg_combined = np.zeros((500, int(178*23)))\n",
        "  labels_combined = np.zeros(500)\n",
        "  labels_chunks = np.zeros((500, 23))\n",
        "  labels_dict = {}\n",
        "  for i in range(len(eeg_df)):\n",
        "    fn = eeg_df.iloc[i]['Unnamed: 0']\n",
        "    subject_id = fn.split('.')[-1]\n",
        "    subject_ind = sub2ind[subject_id]\n",
        "\n",
        "    chunk_id = int(fn.split('.')[0].split('X')[-1])\n",
        "    start_idx = (chunk_id - 1) * 178\n",
        "    end_idx = start_idx + 178\n",
        "    eeg_combined[subject_ind, start_idx:end_idx] = eeg_df.iloc[i].values[1:-1]\n",
        "\n",
        "    if subject_id not in labels_dict:\n",
        "      labels_dict[subject_id] = []\n",
        "    labels_dict[subject_id].append(eeg_df.iloc[i].values[-1])\n",
        "\n",
        "  for sub_id, labels in labels_dict.items():\n",
        "    sub_ind = sub2ind[sub_id]\n",
        "    is_seizure = int(np.any(np.array(labels) == 1))\n",
        "    labels_combined[sub_ind] = is_seizure\n",
        "    labels = np.array(labels)\n",
        "    labels = np.where(labels>1, 0, labels)\n",
        "    labels_chunks[sub_ind,:] = labels\n",
        "\n",
        "  return eeg_combined, labels_combined, labels_chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqWtinpR5Uwx",
        "cellView": "form"
      },
      "source": [
        "#@title ## Download our data set!\n",
        "data_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00388/data.csv'\n",
        "uci_epilepsy = './uci_epilepsy'\n",
        "gdown.download(data_path, uci_epilepsy, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gYoQd5e5a3P",
        "cellView": "form"
      },
      "source": [
        "#@title ## Prepare our data set!\n",
        "\n",
        "eeg = pd.read_csv(uci_epilepsy)\n",
        "x, y, y_time_steps = prepare_data(eeg)\n",
        "\n",
        "# reshape x into (number_of_samples, number_of_time_steps, feature dimension)\n",
        "x = x.reshape(-1, 23, 178).astype(np.float32) \n",
        "np.save('sample', x[30])\n",
        "\n",
        "# reshape y into (num_of_samples, 1)\n",
        "y = y.astype(int).reshape(-1,1) \n",
        "\n",
        "print('Input x shape: ', x.shape)\n",
        "print('Label y shape: ', y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1Gh8BvK5wbP",
        "cellView": "form"
      },
      "source": [
        "#@title ## Train our model!\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2020)\n",
        "\n",
        "# Build a LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the LSTM\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Train the LSTM\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, callbacks=[monitor])\n",
        "\n",
        "# Predict on test data\n",
        "predictions = model.predict(x_test)\n",
        "predictions = predictions > 0.5\n",
        "\n",
        "### END CODE\n",
        "print('Test accuracy: ', accuracy_score(y_test, predictions[:, -1, :]))\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp7Phmim6E8v",
        "cellView": "form"
      },
      "source": [
        "#@title ## Build our web application!\n",
        "\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from joblib import dump, load\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = keras.models.load_model('model.h5')\n",
        "\n",
        "st.title('Epilepsy Detector') \n",
        "uploaded_file = st.file_uploader('Upload Data')\n",
        "if uploaded_file is not None:\n",
        "  data = np.load(uploaded_file).reshape(1, 23, 178)\n",
        "  pred = model.predict(data)\n",
        "  confidence = pred[:, -1, :][0][0]\n",
        "  final_pred = pred > 0.5\n",
        "  final_pred = final_pred[:, -1, :][0][0]\n",
        "  if final_pred == 0:\n",
        "    st.write(f'The model is {round(100 - confidence, 2)}% confident that this patient DOES NOT have epilepsy.') \n",
        "  else:\n",
        "    st.write(f'The model is {round(confidence * 100, 2)}% confident that this patient DOES HAVE have epilepsy.') \n",
        "  st.line_chart(pd.DataFrame(pred.reshape(-1, 1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cB1AwdC7t0x",
        "cellView": "form"
      },
      "source": [
        "#@title ## Run our web application!\n",
        "\n",
        "public_url = ngrok.connect(port='80')\n",
        "print(public_url)\n",
        "!streamlit run app.py >/dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xrt28bzg7wGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990e7a0b-9cce-4d42-efd9-2cbb5e9045f6"
      },
      "source": [
        "#@title If you get an error above, run this to reinitialize Streamlit, then try again!\n",
        "%%writefile ~/.streamlit/config.toml\n",
        "[server]\n",
        "port = 80"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /root/.streamlit/config.toml\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}