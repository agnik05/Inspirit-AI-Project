{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instructor Epilepsy_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqwQhAi2Zvel"
      },
      "source": [
        "# Detecting Epileptic Seizures through EEG Data: Part 1\n",
        "\n",
        "In this project, we'll be trying to figure out whether a person is experiencing a seizure from their EEG reading.\n",
        "\n",
        "## Goals for today:\n",
        "1. Understand what epilepsy is\n",
        "2. Understand what an EEG is\n",
        "3. Visualize an EEG as a time series\n",
        "4. Try out naive ML models (KNNs, logistic regression, etc.) for detecting epilepsy\n",
        "5. Try out a simple neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIjO4zXKZvCt",
        "cellView": "form"
      },
      "source": [
        "#@title ##Import libraries and create helper functions!\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "monitor = ModelCheckpoint('./model.hdf5', \n",
        "                          monitor='val_accuracy', \n",
        "                          verbose=0, \n",
        "                          save_best_only=True, \n",
        "                          save_weights_only=False, \n",
        "                          mode='auto', \n",
        "                          save_freq='epoch')\n",
        "\n",
        "import gdown\n",
        "\n",
        "## Utils function to combine 23 chunks from the same patient into one big chunk\n",
        "# @author Siyi Tang\n",
        "def prepare_data(eeg_df):\n",
        "  file_names = eeg_df['Unnamed: 0'].tolist()\n",
        "\n",
        "  subject_ids = []\n",
        "  chunk_ids = []\n",
        "  for fn in file_names:\n",
        "    subject_ids.append(fn.split('.')[-1])\n",
        "    chunk_ids.append(fn.split('.')[0])\n",
        "  subject_ids = list(set(subject_ids))\n",
        "  assert len(subject_ids) == 500\n",
        "\n",
        "  sub2ind = {}\n",
        "  for ind, sub in enumerate(subject_ids):\n",
        "    sub2ind[sub] = ind\n",
        "\n",
        "  eeg_combined = np.zeros((500, int(178*23)))\n",
        "  labels_combined = np.zeros(500)\n",
        "  labels_chunks = np.zeros((500, 23))\n",
        "  labels_dict = {}\n",
        "  for i in range(len(eeg_df)):\n",
        "    fn = eeg_df.iloc[i]['Unnamed: 0']\n",
        "    subject_id = fn.split('.')[-1]\n",
        "    subject_ind = sub2ind[subject_id]\n",
        "\n",
        "    chunk_id = int(fn.split('.')[0].split('X')[-1])\n",
        "    start_idx = (chunk_id - 1) * 178\n",
        "    end_idx = start_idx + 178\n",
        "    eeg_combined[subject_ind, start_idx:end_idx] = eeg_df.iloc[i].values[1:-1]\n",
        "\n",
        "    if subject_id not in labels_dict:\n",
        "      labels_dict[subject_id] = []\n",
        "    labels_dict[subject_id].append(eeg_df.iloc[i].values[-1])\n",
        "\n",
        "  for sub_id, labels in labels_dict.items():\n",
        "    sub_ind = sub2ind[sub_id]\n",
        "    is_seizure = int(np.any(np.array(labels) == 1))\n",
        "    labels_combined[sub_ind] = is_seizure\n",
        "    labels = np.array(labels)\n",
        "    labels = np.where(labels>1, 0, labels)\n",
        "    labels_chunks[sub_ind,:] = labels\n",
        "\n",
        "  return eeg_combined, labels_combined, labels_chunks\n",
        "\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "  # i'm sorry for this function's code. i am so sorry. \n",
        "  history = history.history\n",
        "  history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "  history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "  best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "  if not ax:\n",
        "    f, ax = plt.subplots(1,1)\n",
        "  sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "  sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "  ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "  ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "  ax.legend(loc = 1)    \n",
        "  ax.set_ylim([0.4, 1])\n",
        "\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel('Accuracy (Fraction)')\n",
        "  \n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-4sm1qQ7PFF",
        "cellView": "form"
      },
      "source": [
        "#@title ## Download our data set!\n",
        "data_path = 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/Deep%20Dives/AI%20%2B%20Healthcare/Projects%20(Session%206%2B)/Seizure%20Prediction%20/data.csv'\n",
        "uci_epilepsy = './uci_epilepsy'\n",
        "gdown.download(data_path, uci_epilepsy, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igv1ZTt_ttaZ"
      },
      "source": [
        "## What is Epilepsy?\n",
        "Epilepsy when someone experiences chronic, uncontrolled seizures.\n",
        "\n",
        "What's a seizure? Read through the **Overview**, **What is a Seizure?**, and **What Causes Seizures** section of [this article](https://mayfieldclinic.com/pe-seizure.htm).\n",
        "\n",
        "Afterwards, read through the **Overview** and **What is Epilepsy?** sections of [this article](https://mayfieldclinic.com/pe-epilepsy.htm). \n",
        "\n",
        "If you have more time, you can continue reading both of these articles to get a better understanding of seizures and epilepsy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf05vDN0t3jr"
      },
      "source": [
        "## What is an EEG (an electroencephalogram)?\n",
        "\n",
        "\n",
        "\n",
        "First, watch this quick [video](https://www.youtube.com/watch?v=tZcKT4l_JZk) on EEG.\n",
        "\n",
        "If you have more time, start to read through [this](https://www.ncbi.nlm.nih.gov/books/NBK390346/) (slightly more technical) introduction ot EEG. The second and the fourth paragraphs especially provide some information that will be relevant to us!\n",
        "\n",
        "Discuss with your group:  \n",
        "What makes EEG an appealing diagnostic tool? \n",
        "What are some things that we need to be wary about when we use EEG?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy5CtxsLzxE9"
      },
      "source": [
        "## Our goal: Use EEGs to detect seizures\n",
        "\n",
        "In order for physicians to treat patients, it's important for them to know if their patients are experiencing epileptic seizures! \n",
        "\n",
        "Can we find seizure-specific patterns in EEGS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pe8r5UmtkGf"
      },
      "source": [
        "# First, let's take a look at our data set!\n",
        "\n",
        "We'll be using the [UCI Epileptic Seizure Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition#)\\*. Click on the link and read the section titled **Attribute Information**. Discuss with your group. What is the input to our machine learning pipeline? What will be the output?\n",
        "\n",
        "Now go ahead and run the cell below to take a look at your data. Check in with your group - do you all understand what each row and each column of the DataFrame represents? What are the units associated with the values?\n",
        "\n",
        "<sub>\\* This data set is a modified version of the data set generated by the authors of [this paper](https://pubmed.ncbi.nlm.nih.gov/11736210/).</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_hHKe9kzrKK"
      },
      "source": [
        "EEG = pd.read_csv(uci_epilepsy)\n",
        "EEG.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgBqVXmeUAKs"
      },
      "source": [
        "If you read over the UCI documentation, you'll know that each patient provided 23 of these rows, because the UCI researchers took every EEG sample that they had and split it into 23 chunks. For reasons we'll get into later, we would prefer to have a single EEG sample per patient.\n",
        "\n",
        "We'll use the helper function *prepare_data* (defined in the Import libraries and create helper functions cell at the beginning of this notebook!) to do just that. Run the code below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Cv070ZVZ58"
      },
      "source": [
        "eeg, labels, __ = prepare_data(EEG)\n",
        "print(\"eeg: \")\n",
        "print(eeg)\n",
        "print(\"labels: \")\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Xpwrt-YAGW"
      },
      "source": [
        "####Discussion: \n",
        "\n",
        "eeg and labels are NumPy arrays, not DataFrames, so they don't format quite as prettily. But this is a good format to have them in for our future work! Before we move on, check your understanding with your classmates:\n",
        "\n",
        "What does each row of the eeg array represent? What does each column represent? What are the units of the measurements?\n",
        "\n",
        "What does each entry in the labels array represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhwYV5AbZP4-",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "# 1 row of eeg = 1 patient's eeg\n",
        "# 1 column of eeg = the samples for every eeg at a particular time\n",
        "# each entry of labels = the classification of the eeg: 1 for seizure, 0 for non-seizure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8UcHDH_ifzu"
      },
      "source": [
        "## Let's visualize one of these EEG samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVk8uDjAaDKJ"
      },
      "source": [
        "First, use [splicing](https://numpy.org/doc/stable/reference/arrays.indexing.html) to extract just one of the EEG samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0pbn3laiKxd"
      },
      "source": [
        "print(\"EEG: \")\n",
        "eeg1 = None ### FILL ME IN ###\n",
        "print(eeg1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hi4VdPoaMbP",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "print(\"EEG: \")\n",
        "eeg1 = eeg[0][:]\n",
        "print(eeg1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1vYpClEO5be"
      },
      "source": [
        "#### Class Discussion:\n",
        "\n",
        "What are the units of each of the numbers in the EEG array?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2nDwtvAOZMV"
      },
      "source": [
        "####It's kind of hard to understand what's going on when we're just looking at a long list of numbers! \n",
        "\n",
        "Let's try plotting the EEG as a **time series** waveform. A time series is term used to refer to a sequence of data points listed in chronological order. Alternatively, we can say that our EEG data exists in the **time domain**. All of our EEG data has been uploaded in time series form! \n",
        "\n",
        "(In our second notebook, we will discuss another way of representing waveforms -- a frequency domain representation.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj_3AC5Ym6Ta"
      },
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(eeg1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvq0MZ3MnfGK"
      },
      "source": [
        "###What are the units of the x axis of this plot? What are the units of the y axis?\n",
        "\n",
        "(Hint: You'll want to review the information given to you here: [UCI Epileptic Seizure Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition#))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEtI0bZJO8bN",
        "cellView": "form"
      },
      "source": [
        "x_units = '' #@param {type:\"string\"}\n",
        "y_units = '' #@param {type:\"string\"}\n",
        "\n",
        "print(\"The y axis units are microvolts and the x axis units are 1/178s of a second.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIx2ToP1OxZK"
      },
      "source": [
        "**We want to change the units of the x axis to seconds**\n",
        "\n",
        "To accomplish that, we can use a numpy function called [linspace](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html). Click on the link to look at linspace's documentation! Use the documentation to fill in the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcYlgxWNs6zW"
      },
      "source": [
        "x = np.linspace(### FILL ME IN ###)\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(x,eeg1)\n",
        "plt.xlabel('Seconds')\n",
        "plt.ylabel('Microvolts')\n",
        "plt.title(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PhCiBZDQCzC",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "# Each EEG = 23.6 seconds\n",
        "# 4094 data points per EEG\n",
        "\n",
        "x = np.linspace(0,23.6,4094) \n",
        "\n",
        "# EEGs tend to be measured in microvolts\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(x,eeg1)\n",
        "plt.xlabel('Seconds')\n",
        "plt.ylabel('Microvolts')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRqDSX5UQa1s"
      },
      "source": [
        "Now that we understand what our data looks like, we can move on to creating classification models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoEaeRflzY82"
      },
      "source": [
        "# Build and Evaluate Naive Models\n",
        "\n",
        "We'll start by using some simple models. When we do any type of machine learning, we follow a standard machine learning pipeline. To remind yourself of our workflow, correctly order the pipeline steps below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w30mHr1Q5xS",
        "cellView": "form"
      },
      "source": [
        " #@title Machine Learning Pipeline\n",
        " \n",
        " one = 'Collect input and output data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        " two = 'Collect input and output data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        " three = 'Collect input and output data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        " four = 'Collect input and output data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        " five = 'Collect input and output data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwL-L7H1dilS",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "print(\"1.Collect input and output data\")\n",
        "print(\"2. Split the data into training and testing data sets\")\n",
        "print(\"3. Create the model\")\n",
        "print(\"4. Fit the model to the training data\")\n",
        "print(\"5. Test the model's accuracy with the testing data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we1xNYzY3aVp"
      },
      "source": [
        "### First, we need input and output arrays for our ML pipeline. \n",
        "\n",
        "Luckily, our eeg and labels arrays are almost ready. We'll just make one or two modifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6giFCiVUzOCZ"
      },
      "source": [
        "x = eeg.astype('float')\n",
        "y = labels.astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uUk3UAJeNVz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnko1d0U6SEm"
      },
      "source": [
        "### Next, split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjUIYAeO6WUJ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAgEuQ3m5-E_"
      },
      "source": [
        "### Let's build some models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St5mYH_g5ep7"
      },
      "source": [
        "Here are some models in sklearn that we learned about last week! \n",
        "* `knn = KNeighborsClassifier(n_neighbors = 5)`\n",
        "* `log = LogisticRegression()`\n",
        "* `dt = DecisionTreeClassifier(max_depth = 2)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX_5p0YP_PMV"
      },
      "source": [
        "Try all 3 models, and try varying the parameter value for the KNN and DT models. What is the highest accuracy you can achieve on the test set with `accuracy_score`? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q98FFoh76ELB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljC0IoobcS0i",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "## BEST ACCURACIES:\n",
        "## KNN, n_neighbors=1, acc=~85%\n",
        "## DT, max_depth=10, acc=~89%\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10)      \n",
        "knn.fit(x_train, y_train)\n",
        "predictions = knn.predict(x_test)\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "print(acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOEdNw0-9rCp"
      },
      "source": [
        "### Discussion: How well did we do?\n",
        "\n",
        "Some things to consider:\n",
        "* How well would we have done if we had just classified each EEG randomly?\n",
        "* What type of accuracy is needed for this problem?\n",
        "* Are false positives or false negatives more alarming?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL0Soa_FZlVU"
      },
      "source": [
        "# Compute the confusion matrix for the test data using confusion_matrix function\n",
        "conf_mat = confusion_matrix(y_test, predictions)\n",
        "cm_display = ConfusionMatrixDisplay(conf_mat, display_labels=np.arange(2)).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDHH2p0d5VyW"
      },
      "source": [
        "# Build a Simple Neural Net\n",
        "\n",
        "Let's try out a model that's a little more complicated. Neural networks look something like this: \n",
        "\n",
        "![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhID1519AYF8"
      },
      "source": [
        "But how can we create this model in Python? Here' some code that will create the neural network picture above. We're going to use the tensorflow and keras libraries to create our neural network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yus22AQpsqMH"
      },
      "source": [
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import optimizers\n",
        "\n",
        "# create our model by specifying and compiling it\n",
        "model = Sequential()\n",
        "model.add(Dense(7, input_shape=(5,),activation = 'relu'))\n",
        "model.add(Dense(7, activation = 'relu'))\n",
        "model.add(Dense(4, activation = 'linear'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['mean_squared_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "781M4IyhssuA"
      },
      "source": [
        "**Can you explain what each step does here?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRRHFpDs7vxn"
      },
      "source": [
        "###Your Assignment: \n",
        "Make a neural network with two hidden layers that have ReLU activation. \n",
        "The first layer should have 128 neurons. \n",
        "\n",
        "The second layer should have 64 neurons. \n",
        "\n",
        "Then you should have one output layer with sigmoid activation. \n",
        "\n",
        "Use the sample neural net created above as a starting place! You can use the same loss, optimizer, and metrics in your compile command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NAcF5VTBfzb"
      },
      "source": [
        "nn = Sequential()\n",
        "### TODO: YOUR CODE HERE! ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBKhrt7T8wFg"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "out_activation = 'sigmoid' \n",
        "loss_fxn = 'binary_crossentropy'\n",
        "\n",
        "nn = Sequential()\n",
        "nn.add(Dense(128, input_shape = (x.shape[1],), activation = 'relu'))\n",
        "nn.add(Dense(64, activation = 'relu'))\n",
        "nn.add(Dense(units = 1, activation = out_activation))\n",
        "nn.compile(loss= loss_fxn,\n",
        "           optimizer = 'adam', \n",
        "           metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMKbG2IqCs3W"
      },
      "source": [
        "Now run the code below to train your network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhGq5OhGCpZS"
      },
      "source": [
        "nn.fit(x_train, y_train, epochs = 100, validation_data = (x_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(nn.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1bepgbv8VvE"
      },
      "source": [
        "**What problem is your model experiencing?** How could we address it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPa31of98gUH"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "One way to address overfitting is by introducing [dropout](https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/). Read the linked article to understand what dropout is. \n",
        "\n",
        "Then copy your model from above into the cell below, and add dropout to one or more of your layers! Train your model and plot its accuracy. Play around with different dropout values. Were you able to reduce overfitting? By how much?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P_1d4O4D4KK"
      },
      "source": [
        "## TODO: YOUR CODE HERE ## \n",
        "# Copy your model from above! Then add dropout."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGL69GxDEEWf"
      },
      "source": [
        "nn.fit(x_train, y_train, epochs = 100, validation_data = (x_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(nn.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pcqlkqBXgrA",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "# I have gotten 85% acc with 0.2 dropout added after both hidden layers\n",
        "# Sometimes this set up also gets as low as 74% acc - discuss with students!\n",
        "out_activation = 'sigmoid' \n",
        "loss_fxn = 'binary_crossentropy'\n",
        "dropout = 0.2\n",
        "\n",
        "nn = Sequential()\n",
        "nn.add(Dense(128, input_shape = (x.shape[1],), activation = 'relu'))\n",
        "nn.add(Dropout(dropout))\n",
        "nn.add(Dense(64, activation = 'relu'))\n",
        "nn.add(Dropout(dropout))\n",
        "nn.add(Dense(units = 1, activation = out_activation))\n",
        "nn.compile(loss= loss_fxn,\n",
        "           optimizer = 'adam', \n",
        "           metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "nn.fit(x_train, y_train, epochs = 100, validation_data = (x_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(nn.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlQ-5EI-IKes"
      },
      "source": [
        "#### You may have also noticed that your accuracy sometimes changes when you retrain the same neural net. Why does this happen? Discuss with your classmates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3DesqIMIUG1"
      },
      "source": [
        "# You've finished this notebook ðŸ˜Š Congrats!"
      ]
    }
  ]
}