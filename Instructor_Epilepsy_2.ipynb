{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instructor Epilepsy_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlJ9AbccijL9"
      },
      "source": [
        "# Detecting Epileptic Seizures through EEG Data: Part 2\n",
        "\n",
        "In this project, we'll be trying to figure out whether a person is experiencing a seizure from their EEG reading.\n",
        "\n",
        "## Goals for today:\n",
        "1. Introduction to signal processing\n",
        "2. Create EEG spectrograms\n",
        "3. Understand what a CNN is\n",
        "4. Use a CNN to classify EEG spectrograms\n",
        "5. Limitations of CNNs for time series data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvwyXB1zieuP",
        "cellView": "form"
      },
      "source": [
        "#@title ##Import libraries and create helper functions!\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install hypopt\n",
        "from hypopt import GridSearch\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "monitor = ModelCheckpoint('./model.hdf5', \n",
        "                          monitor='val_accuracy', \n",
        "                          verbose=0, \n",
        "                          save_best_only=True, \n",
        "                          save_weights_only=False, \n",
        "                          mode='auto', \n",
        "                          save_freq='epoch')\n",
        "\n",
        "import gdown\n",
        "\n",
        "## Utils function to combine 23 chunks from the same patient into one big chunk\n",
        "# @author Siyi Tang\n",
        "def prepare_data(eeg_df):\n",
        "  file_names = eeg_df['Unnamed: 0'].tolist()\n",
        "\n",
        "  subject_ids = []\n",
        "  chunk_ids = []\n",
        "  for fn in file_names:\n",
        "    subject_ids.append(fn.split('.')[-1])\n",
        "    chunk_ids.append(fn.split('.')[0])\n",
        "  subject_ids = list(set(subject_ids))\n",
        "  assert len(subject_ids) == 500\n",
        "\n",
        "  sub2ind = {}\n",
        "  for ind, sub in enumerate(subject_ids):\n",
        "    sub2ind[sub] = ind\n",
        "\n",
        "  eeg_combined = np.zeros((500, int(178*23)))\n",
        "  labels_combined = np.zeros(500)\n",
        "  labels_chunks = np.zeros((500, 23))\n",
        "  labels_dict = {}\n",
        "  for i in range(len(eeg_df)):\n",
        "    fn = eeg_df.iloc[i]['Unnamed: 0']\n",
        "    subject_id = fn.split('.')[-1]\n",
        "    subject_ind = sub2ind[subject_id]\n",
        "\n",
        "    chunk_id = int(fn.split('.')[0].split('X')[-1])\n",
        "    start_idx = (chunk_id - 1) * 178\n",
        "    end_idx = start_idx + 178\n",
        "    eeg_combined[subject_ind, start_idx:end_idx] = eeg_df.iloc[i].values[1:-1]\n",
        "\n",
        "    if subject_id not in labels_dict:\n",
        "      labels_dict[subject_id] = []\n",
        "    labels_dict[subject_id].append(eeg_df.iloc[i].values[-1])\n",
        "\n",
        "  for sub_id, labels in labels_dict.items():\n",
        "    sub_ind = sub2ind[sub_id]\n",
        "    is_seizure = int(np.any(np.array(labels) == 1))\n",
        "    labels_combined[sub_ind] = is_seizure\n",
        "    labels = np.array(labels)\n",
        "    labels = np.where(labels>1, 0, labels)\n",
        "    labels_chunks[sub_ind,:] = labels\n",
        "\n",
        "  return eeg_combined, labels_combined, labels_chunks\n",
        "\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "  # i'm sorry for this function's code. i am so sorry. \n",
        "  history = history.history\n",
        "  history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "  history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "  best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "  if not ax:\n",
        "    f, ax = plt.subplots(1,1)\n",
        "  sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "  sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "  ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "  ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "  ax.legend(loc = 1)    \n",
        "  ax.set_ylim([0.4, 1])\n",
        "\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel('Accuracy (Fraction)')\n",
        "  \n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5x76pEyjPIe"
      },
      "source": [
        "#@title Run this to get the x and y datasets we created last class\n",
        "\n",
        "data_path = 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/Deep%20Dives/AI%20%2B%20Healthcare/Projects%20(Session%206%2B)/Seizure%20Prediction%20/data.csv'\n",
        "uci_epilepsy = './uci_epilepsy'\n",
        "gdown.download(data_path, uci_epilepsy, False)\n",
        "\n",
        "\n",
        "EEG = pd.read_csv(uci_epilepsy)\n",
        "eeg, labels, __ = prepare_data(EEG)\n",
        "x = eeg.astype('float')\n",
        "y = labels.astype('float')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUmH04Jb5OJJ"
      },
      "source": [
        "len(eeg[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4aH6dFfT2u8"
      },
      "source": [
        "## Introduction to the Frequency Domain\n",
        "So far, we've been looking at our data in the time domain. What that means is that we're looking our EEG as a series of values in time. (In other words, if we plot our EEG, the x-axis, or the *domain* of the plot has units of time!\n",
        "\n",
        "We can also choose to explore our data in the *frequency domain*. In the frequency domain, the x axis of our plot is the frequency of the signal. \n",
        "\n",
        "To understand the frequency domain, we need to start by understanding the composition of our EEG data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glLI61KsQJy5"
      },
      "source": [
        "**This next part is going to get a little technical! Don't worry if it doesn't completely make sense right now - you can still complete this project without fully understanding this part.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwAofzL4IaUm"
      },
      "source": [
        "###Introduction to Waves\n",
        "\n",
        "EEG data is a waveform - a signal that consists of a single amplitude that changes in time. (Sound, radio signals, and seismic waves are also waveforms!)\n",
        "\n",
        "The simplest type of waveform is a sinusoidal wave. A sinusoidal wave is a function made of the sum of sine and cosine functions. The most basic sinusoid function is just a single sine wave. A generic sine wave is shown below:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1BB_0nwPMvDEkDL9vM-HbYUelHnjYU6vg)\n",
        "\n",
        "\n",
        "The important parts of this wave are the **frequency** (how quickly the wave alternates in time) and the **amplitude** (how tall the wave is). This wave is mathematically represented by the formula:\n",
        "\n",
        "$y(t) = A*sin(\\dfrac{2\\pi}{\\lambda}t + \\phi)$\n",
        "\n",
        "In the above case, $\\phi = 0$! We can also have a non-zero $\\phi$. A non-zero value of $\\phi$ will shift the wave to the left (if $\\phi > 0$) or to the left (if $\\phi < 0$), as shown below:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1gp1HjKRuUO-VOBfDeJeuMD4VF8X_FA1X)\n",
        "\n",
        "(In the above picture, $\\dfrac{2\\pi}{\\lambda}$ is simplified to $\\omega$ but it's the same form of wave!) $\\phi$ is known as the **phase** of the wave.\n",
        "\n",
        "These three variables (amplitude, frequency, and phase) determine the shape of the sine wave.\n",
        "\n",
        "\n",
        "If you're not familiar with waves, you might consider going over [these](https://www.mathsisfun.com/physics/waves-introduction.html) [two](https://www.mathsisfun.com/algebra/amplitude-period-frequency-phase-shift.html) quick primers from Math is Fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7BDP4iOQWi0"
      },
      "source": [
        "### Representing EEG waves as Sine Waves\n",
        "\n",
        "It's cool that we can represent a wave as a simple mathematical formula, but our EEG data looks a lot messier than the waves we saw above! For reference, here's the EEG we plotted in Colab 1: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2LkbvGvRmhW"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1G3KK6LBKX1Iiz4dV2nt2LXnWSuWkv3IU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkXRI9YBSQdr"
      },
      "source": [
        "This looks very different from our simple sine waves, but it turns out that we can represent it pretty well as a sum of sinusoids - a bunch of sinusoids with different amplitudes, different phases, and different frequencies all added on top of each other!\n",
        "\n",
        "Here's an example of how this process can work:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1JIguickzYUJ3Y4N_8VQDlwJ0jwQIC3q8)\n",
        "\n",
        "The red wave at the bottom is the sum of the blue and green waves.\n",
        "\n",
        "This is still a pretty simple waveform, but it turns out if we add hundreds of different sine waves (all with different amplitudes, frequencies, and phases), then we can accurately represent most EEG signals!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgh7ThFwWpRv"
      },
      "source": [
        "### So... how does this relate to the frequency domain?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IWcQzVOWxpC"
      },
      "source": [
        "If we know that an EEG is formed as the sum of a sine waves with different frequencies, we can plot those sine waves on a frequency axis. \n",
        "\n",
        "This is done in the picture below: we have one signal that is formed as the sum of two sinusoids. We can represent that signal by projecting it on to the time domain (the way we've been looking at it so far!) or we can represent that signal by projecting it on to the frequency domain (the projection pictured on the right side of the picture).\n",
        "\n",
        "![](https://drive.google.com/uc?id=1wO2Lw0JLdCZNP1dk3Lggy9Pes8tq1cLy)\n",
        "\n",
        "This signal looks a lot simpler in the frequency domain! It can be described as just two spikes at two different frequencies. The frequency domain can be a really useful way for us to represent signals, for purposes of clarity, compression, filtering, and, in our case, classification!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ivgH_i62qD7"
      },
      "source": [
        "We're going to look at a specific way to project a signal into the frequency domain, called a spectrogram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCmQuXwmjsx1"
      },
      "source": [
        "### Introduction to Spectrograms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7qYJHuTZ7CN"
      },
      "source": [
        "There's only one problem with representing our EEG signals in the frequency domain, and that's that the frequencies in an EEG signal can change over time!\n",
        "\n",
        "TODO\n",
        "\n",
        "https://drive.google.com/uc?id=<ID of image>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50cJIrWeUA5y"
      },
      "source": [
        "## Create EEG Spectrograms for our dataset\n",
        "Similarly to how we visualized one EEG as a time series in the first notebook, we will now visualize that same EEG as a spectrogram.\n",
        "\n",
        "Then we will convert all of our EEGs to spectrograms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39CwnX22fXnr"
      },
      "source": [
        "In order to convert an EEG to a spectrogram, we will need to understand what the *sampling rate ($f_s$)* of the data is. The sampling rate of the data is the number of samples taken per second. \n",
        "\n",
        "Review the [UCI Epileptic Seizure Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition#) **Attribute Information** section to figure out how many seconds of EEG recordings were taken per patient. Remember: while the UCI data talks about 'chunks' of EEG, we have recombined those chunks into one continuous data stream per person for the purposes of this notebook! So we're looking for the number of seconds of recording per patient, not per chunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARD-VinUtcjl",
        "cellView": "form"
      },
      "source": [
        "#@title What is the length of each EEG in seconds?\n",
        "duration =  23.5#@param {type:\"number\"}\n",
        "\n",
        "if duration == 23.5:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Hmm, that's not correct. Try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCgu4ybRuy7v",
        "cellView": "form"
      },
      "source": [
        "#@title How many data points (samples) are in one EEG?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBjJ8BfQ5wrx"
      },
      "source": [
        "num_samples = ### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbRVV5j52DQ",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "num_samples = len(eeg[0])\n",
        "print(\"Number of samples is: \"+str(num_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8mu2N3pUent"
      },
      "source": [
        "# Calculate the sampling rate from the duration and number of samples in each EEG!\n",
        "fs = num_samples/duration\n",
        "\n",
        "# set spectrogram parameters\n",
        "nfft = 32\n",
        "overlap = 16\n",
        "\n",
        "# Extract first EEG sample\n",
        "eeg1 = x[0,:]\n",
        "\n",
        "# Plot spectrogram\n",
        "Sxx, f, t, imageAxis = plt.specgram(eeg1, Fs=fs, NFFT=nfft, noverlap=overlap)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJT4HYuV6EDs"
      },
      "source": [
        "### Next, let's convert all of our EEGs to spectrograms\n",
        "Note: this step may take a while!\n",
        "\n",
        "TODO: GPU Instructions?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY4wpocpyITd"
      },
      "source": [
        "# Convert all the EEGs to spectrograms\n",
        "x_spec = []\n",
        "for eeg in x:\n",
        "  Sxx, f, t, imageAxis = plt.specgram(eeg, Fs=fs, NFFT=nfft, noverlap=overlap)\n",
        "  x_spec.append(Sxx)\n",
        "\n",
        "x_spec = np.array(x_spec)\n",
        "print(x_spec.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtjzszLyUM5y"
      },
      "source": [
        "## Let's use convolutional neural nets on our spectrograms!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZTo0cpb9uOR"
      },
      "source": [
        "We've turned our EEGs into spectrograms, which are fancy pictures. ...what type of classifier works well on pictures?\n",
        "\n",
        "CNNs!\n",
        "\n",
        "It may be worth it to review the notebook and slide deck for CNNs before you go forward. \n",
        "\n",
        "Next, remind yourself of our machine learning pipeline below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEUvPJbxbUJP",
        "cellView": "form"
      },
      "source": [
        "#@title Machine Learning Pipeline\n",
        " \n",
        "one = 'Split the data into training and testing data sets' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        "two = 'Create the model' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        "three = 'Fit the model to the training data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        "four = 'Test the model on the testing data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]\n",
        "five = 'Collect input and output data' #@param [\"Collect input and output data\", \"Fit the model to the training data\", \"Create the model\", \"Split the data into training and testing data sets\", \"Test the model on the testing data\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghrjM2nLbi_-"
      },
      "source": [
        "First, we'll do a little reshaping of our data to make it fit our CNN. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP0JbfGnDHhR",
        "cellView": "both"
      },
      "source": [
        "x_spec_reshaped = np.reshape(x_spec,(x_spec.shape[0],x_spec.shape[1],x_spec.shape[2],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJdS5741_iD-"
      },
      "source": [
        "How does our data change after reshaping? Try comparing the shape of our data before and after our transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oelQTT1N-xIA"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCH5DfqtAMoe"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "print(x_spec.shape)\n",
        "print(x_spec_reshaped.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A46XhsNQAUYR"
      },
      "source": [
        "We had to make this modification, since by default, Tensorflow models expect image data to be shaped in the format `[NUM_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS]`. What does `NUM_CHANNELS` signify? Well, an RGB color image would have three channels for every pixel. Each channel would either convey the red, blue, or green information of that pixel. However, in our case, since our image is grayscale, how many channels would our image have? What would that channel signify?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh9g6lccBTrM"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1raEOu1CBWFF"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# The 1 channel represents the pixel's grayscale value between 0 and 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GeIVVZJ--IK"
      },
      "source": [
        "Next, we need to split our x_spec and y data into training and testing data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjUIYAeO6WUJ"
      },
      "source": [
        "x_spec_reshaped = x_spec_reshaped.astype('float')\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_spec_reshaped, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7dLTDk1a3Jr"
      },
      "source": [
        "Let's start off with creating our CNN model! This is the basic skeleton for a Keras CNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oLLPdIja-gb"
      },
      "source": [
        "cnn = Sequential()\n",
        "\n",
        "# Your Layers Here\n",
        "\n",
        "opt = keras.optimizers.SGD(lr=1e-6, momentum=0.95)\n",
        "cnn.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy']) \n",
        "\n",
        "cnn.add(Dense(1))\n",
        "cnn.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSvwSoSzJEsB"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "cnn = Sequential()\n",
        "\n",
        "cnn.add(Conv2D(64, (3, 3)))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(64, (3, 3)))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "\n",
        "cnn.add(Dense(128))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(Dense(64))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Dense(1))\n",
        "cnn.add(Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.SGD(lr=1e-6, momentum=0.95)\n",
        "cnn.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmiPqFA-J7nO"
      },
      "source": [
        "Taking a look at the code above, what do the following lines do:\n",
        "1.   `cnn = Sequential()`\n",
        "2.   `cnn.compile()`\n",
        "3.   `cnn.add()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBf0l1OWKS7V"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQcCPK2lKgVO"
      },
      "source": [
        "Recall that CNNs require convolutional layers and max pooling layers to \"Extract features\" from images. On a high level how do both of those layers work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68x7StroKePl"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3BJHnI5Lr7N"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# Refer to the CNN review at the bottom of the notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY83dJk7KyEG"
      },
      "source": [
        "How would we add them to our model with code?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j86Dt0hMK0-s"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKyYL25hL2Fm"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# Refer to the CNN review at the bottom of the notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm34MR8xBowU"
      },
      "source": [
        "Now, go back up to our CNNs and add sets of (convolutional + max pooling) layers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7xEJFQ4LQ6d"
      },
      "source": [
        "Also recall that we used \"image flattening\" and \"fully connected layers\" to turn our images into probabalistic outputs for classification. Once again, on a high level how do both of those layers work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnZ8_bGfLhAW"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZIW3IlWL2jw"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# Refer to the CNN review at the bottom of the notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GpaZZnkLix-"
      },
      "source": [
        "How would we add them to our model with code?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbMnCGbLLix-"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlwwhqG2L2xl"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# Refer to the CNN review at the bottom of the notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJvkLqWFIrC-"
      },
      "source": [
        "Once again, go up to our skeleton model's definition and add our flattening and fully connected \"Dense\" layers. Below, there's an example of what your code could look like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7hCcwCRGMCt"
      },
      "source": [
        "\n",
        "Once that you've finalized your model's architecture, let's train it and view its accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-S5z0h3F36d"
      },
      "source": [
        "cnn.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(cnn.history)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLY4oxvBHRXN"
      },
      "source": [
        "Now, go back and revise your model's architecture and edit your hyperparameters. Could you use more training epochs? Do you need more convolutional layers? Once you've made your edits, let's train our model again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R8OKxrfHjVG"
      },
      "source": [
        "cnn.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(cnn.history)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfKxfGGUI7n6"
      },
      "source": [
        "Great job! What are some other ways we could increase our model's performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1B0ZbmXJALT"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcAcMrThJBjM"
      },
      "source": [
        "What if we could use an automated method to test out a range of possible hyperparameters and model architectures? For that, we can use a grid search!\n",
        "\n",
        "A grid search iterates through all the parameters you specify, and creates/tests a new model for all the possible parameter combinations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-tTf_CIKBhM"
      },
      "source": [
        "param_grid = {\n",
        "              'epochs' :              [20, 30, 40],\n",
        "              'layers' :              [1, 2, 4],\n",
        "              'dropout' :             [0.2, 0.3, 0.5],\n",
        "              'activation' :          ['relu', 'elu']\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpSXy-WkKDP7"
      },
      "source": [
        "How many models would be created and tested with the following parameter grid?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89U_M96KPge"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTqjuKOyGYC1"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# There would be 54 models created in total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axpWh_sKKaM8"
      },
      "source": [
        "Let's use the following class as our Grid Search CNN. Feel free to edit the model's arcitecture. Be sure to note however, that the model's architecture and hyperparameters are set through the class's initialization function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnrL7T0ULt3c"
      },
      "source": [
        "#@title Run this to Define our Grid Search CNN Class { display-mode: \"form\" }\n",
        "class gridSearchCNN():\n",
        "    \n",
        "    keras_model = None\n",
        "    model = Sequential()\n",
        "    #epochs=10\n",
        "    epochs=30\n",
        "    batch_size=10\n",
        "    layers=2\n",
        "    dropout=0.5\n",
        "    activation='relu'\n",
        "    \n",
        "    def __init__(self, **params):\n",
        "      pass\n",
        "  \n",
        "    def fit(self, X, y, sample_weight = None):\n",
        "        print(\"Fitting\")\n",
        "        self.keras_model.fit(X,y)\n",
        "        print(\"Fitted \\n\")\n",
        "        return self.keras_model\n",
        "    def predict(self, X):\n",
        "        return self.keras_model.predict(X)\n",
        "    def predict_proba(self, X):\n",
        "        return self.keras_model.predict_proba(X)\n",
        "    def score(self, X, y, sample_weight = None):\n",
        "        print(\"Scoring\")\n",
        "        score = self.keras_model.score(X,y)\n",
        "        print(\"Scored \\n\")\n",
        "        return score\n",
        "        #y_pred = self.keras_model.predict(X)\n",
        "        #roc_auc_score_val = roc_auc_score(y, y_pred)\n",
        "        #return roc_auc_score_val\n",
        "                \n",
        "    def createKerasCNN(self,):\n",
        "      \n",
        "      def create_model():\n",
        "        self.model = Sequential() \n",
        "        self.model.add(Reshape((x_spec.shape[1],x_spec.shape[2], 1)))\n",
        "        \n",
        "        for i in range(self.layers):\n",
        "          self.model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "          self.model.add(Activation(self.activation))\n",
        "        \n",
        "        self.model.add(Conv2D(64, (3, 3)))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Dropout(self.dropout / 2.0))\n",
        "\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(128))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(Dense(64))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(Dropout(self.dropout))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.add(Activation('sigmoid'))\n",
        "\n",
        "\n",
        "        opt = keras.optimizers.SGD(lr=1e-6, momentum=0.95)\n",
        "        self.model.compile(loss='binary_crossentropy',\n",
        "                      optimizer=opt,\n",
        "                      metrics=['accuracy'])\n",
        "        \n",
        "        return self.model\n",
        "\n",
        "      return KerasClassifier(build_fn=create_model, epochs=self.epochs, \n",
        "                            batch_size=self.batch_size, verbose=2)\n",
        "\n",
        "    def get_params(self, deep = True):\n",
        "        return {\n",
        "            'epochs': self.epochs,\n",
        "            'batch_size': self.batch_size,\n",
        "            'layers': self.layers,\n",
        "            'dropout': self.dropout,\n",
        "            'activation': self.activation\n",
        "            }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "      if 'epochs' in params.keys():\n",
        "        self.epochs = params['epochs']\n",
        "      if 'batch_size' in params.keys():\n",
        "        self.batch_size = params['batch_size']\n",
        "      if 'layers' in params.keys():\n",
        "        self.layers = params['layers']\n",
        "      if 'dropout' in params.keys():\n",
        "        self.dropout = params['dropout']\n",
        "      if 'activation' in params.keys():\n",
        "        self.activation = params['activation']\n",
        "      \n",
        "      self.keras_model = self.createKerasCNN()\n",
        "      return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvnCa3DQLc8U"
      },
      "source": [
        "Define a parameter grid that has fewer possible hyperparameters. This is so that we can decrease our execution time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CsskLIjLygL"
      },
      "source": [
        "param_grid = {\n",
        "              # Your Code Here \n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCZRa0mpLnxL"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "param_grid = {\n",
        "              'epochs' :              [1, 2],\n",
        "              'dropout' :             [0.2, 0.3],\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1hOIshNN2MU"
      },
      "source": [
        "However, since we are manually editing the parameters for the model, we need to validate these \"parameter tuned models\" on a seperate dataset.\n",
        "\n",
        "Why would that be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t639Q12HODsi"
      },
      "source": [
        "# Your Response Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq905WUuOE76"
      },
      "source": [
        "This additional slice of our dataset is called the \"validation set.\" Now, let's perform the **test, train, and validation** splits!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqLtL76RCFwB"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssl_V4jnOFZ6"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_spec, y, test_size=0.2)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgYjMWRtM9b7"
      },
      "source": [
        "Now, let's implement our grid search! We'll be the `GridSearch()` function from the `hypopt` library for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_ru-EP3LJpt"
      },
      "source": [
        "gs = GridSearch(model=gridSearchCNN(),param_grid=param_grid,parallelize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjIAnuF8CUUL"
      },
      "source": [
        "Now that we've created our GridSearch model, we can go ahead and use the `.fit()` and `.score()` functions to train our model and evaluate its performance! Also, make sure you're using the correct dataset slices for each step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FamYatf5ChV9"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp8vbNmrNXlc"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "gs.fit(x_train, y_train, x_val, y_val,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnFz-3ZPOs6k"
      },
      "source": [
        "Now let's evaluate our best model's accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vpKTsy-CjK1"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oj6F-IeO6YD"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "gs.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOKjONHnOyas"
      },
      "source": [
        "Great job! We've now created multiple grid search optimized CNNs! Go back and edit your Grid Search parameters to include more variables. Do more layers result in better performance? What dropout value works best? Do certain activation functions work better than others?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxlWGqAGH07-"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snF4RFWNUXyE"
      },
      "source": [
        "## Limitations of CNNs for spectrogram classification\n",
        "\n",
        "This method seems pretty cool! Any drawbacks? Take a look at [this article](https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd). Do the arguments that the author makes for about why CNNs could not be the best way to analyze audio signals also apply to EEG signals? Why or why not? Discuss with your classmates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkeOk7xvZesT"
      },
      "source": [
        "# You've finished this notebook 😊 Congrats!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcMw9Vr6H8nh"
      },
      "source": [
        "# Extra CNN Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBMo8mas9rHd"
      },
      "source": [
        "Let's take a look at an example of a CNN's architecture.\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)\n",
        "\n",
        "The first segment of the CNN applies transformations to the image itself. As the images passes through these layers, \"features\" are identified which can be used to distinguish between the classes. \n",
        "The most important layers in this part of the CNN are convolutional and max pooling layers. \n",
        "\n",
        "Convolutional layers look through the image in a sliding window, and extract the features. An example of a line in Python adding a convolutional layer is `cnn.add(Conv2D(64, (3, 3), padding='same'))`. You can specify the model's activation function by adding `cnn.add(Activation(activation)) `after the convolutional layer's definition.\n",
        "\n",
        "Max pooling layers decrease the resolution of the image. This is to reduce the complexity of the image (less pixels) and prevent the model from overfitting. An example of a line oin Python adding a max pooling layer is `cnn.add(MaxPooling2D(pool_size=(2, 2)))`.\n",
        "\n",
        "<!---Dropout layers are layers in which some neurons are randomly removed from a layer during training. These can be used to prevent overfitting during training by temporarily reducing the model's complexity. The code to add a dropout layer is `cnn.add(Dropout(dropout))`.--->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEkWtCDMevvU"
      },
      "source": [
        "Now, let's translate the above CNN architecture into code.\n",
        "\n",
        "We start with `cnn = Sequential()` which defines that our CNN will be linearly structured. This means that every layer in the model uses the ouput of the previous layer as its input.\n",
        "\n",
        "`Reshape` ensures that the input `x_spec` shape is consistent with the shape of the convolutional filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IciEtD7fS5F"
      },
      "source": [
        "## Define number of layers and loss function\n",
        "np.expand_dims(x_spec, 2)\n",
        "num_hidden_layers = 2 # reduced this (Raghav)\n",
        "loss_fxn = 'binary_crossentropy'\n",
        "\n",
        "## Our CNN will be linearly structured\n",
        "cnn = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl4sUftwfTdL"
      },
      "source": [
        "Next, we sequentially add layers to the CNN such as convolutional layers and max pooling layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPwZzAJ1fqBF"
      },
      "source": [
        "cnn.add(Reshape((x_spec.shape[1],x_spec.shape[2], 1))) # added this (Raghav)\n",
        "cnn.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "for i in range(num_hidden_layers-1):\n",
        "    cnn.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "    cnn.add(Activation('relu'))\n",
        "    cnn.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkrjpFMLDN6N"
      },
      "source": [
        "Now, let's move onto the second major component of CNNs, the fully connected layers. After the image has been transformed in all of the previous CNN layers, we need to actually classify the image. We need to somehow convert the image into a probability of the image pertaining to a class.\n",
        "\n",
        "To do this, we first **flatten** the image. With image flattening, we can represent a 2D matrix (image) as a 1D array (feature vector). \n",
        "\n",
        "![alt text](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png)\n",
        "\n",
        "We need to perform this transformation so that our neural network can take in our image data. You can add aflattening layer using `cnn.add(Flatten())` We can then construct a neural network and add layers using `model.add(Dense(128))` and specifying the activation function with `cnn.add(Activation(activation))`. You can also add dropout layers here as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvq_l2rLikts"
      },
      "source": [
        "## Flatten the 2D matrix into 1D array\n",
        "cnn.add(Flatten()) \n",
        "\n",
        "## Add dense (fully connected) layers\n",
        "cnn.add(Dense(units = 128, activation = 'relu'))\n",
        "#cnn.add(Dropout(dropout))\n",
        "cnn.add(Dense(units = 64, activation = 'relu'))\n",
        "\n",
        "## The last dense layer produces the output probability, and thus need a sigmoid activation\n",
        "cnn.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DQ1EHWogwES"
      },
      "source": [
        "Once we are done definining the CNN architecture, we also need to determine the performance metric we want to use the evaluate our model and the optimization function to optimize the model parameters. We can then compile the model using `cnn.compile()`.\n",
        "\n",
        "Finally, we can train the model with `cnn.fit()`, and visualize its performance over time with `plot_acc()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUvPJ5gDhNgZ"
      },
      "source": [
        "## Train the model using RMSprop optimizer and accuracy as the performance metric\n",
        "cnn.compile(loss=loss_fxn,\n",
        "            optimizer=keras.optimizers.SGD(lr=1e-6, momentum=0.95),\n",
        "            metrics=['accuracy']) \n",
        "\n",
        "cnn.fit(x_train, y_train, epochs = 100, validation_data = (x_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "\n",
        "## Plot accuracy over time\n",
        "plot_acc(cnn.history) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}